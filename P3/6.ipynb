{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fda9504c-2b68-4cb7-80e4-746e12cfce23",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3922091208.py, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Johanz\\AppData\\Local\\Temp\\ipykernel_8476\\3922091208.py\"\u001b[1;36m, line \u001b[1;32m70\u001b[0m\n\u001b[1;33m    record.value.index = [:] # Clear the bucket\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Function to convert a key to its binary hash representation\n",
    "def hash_function(key):\n",
    "    return '{0:016b}'.format(key)\n",
    "\n",
    "#Initializes bucket\n",
    "class Bucket:\n",
    "    def __init__(self, local_depth, index, empty_spaces, id):\n",
    "        self.id = id #Bucket ID\n",
    "        self.local_depth = local_depth #Local depth of bucket\n",
    "        self.index = index #List of numbers in a bucket\n",
    "        self.empty_spaces = empty_spaces #Empty spaces in a bucket\n",
    "\n",
    "#Initializes directory\n",
    "class Directory:\n",
    "    def __init__(self, global_depth, directory_records):\n",
    "        self.global_depth = global_depth #Global depth of directory\n",
    "        self.directory_records = directory_records #List of directory records\n",
    "\n",
    "#Initializes directory record        \n",
    "class DirectoryRecord:\n",
    "    def __init__(self, bucket, hash_prefix):\n",
    "        self.hash_prefix = hash_prefix #Hash prefix for directory record\n",
    "        self.value = bucket #Bucket associated with directory record\n",
    "\n",
    "bucket_capacity = 3 #Capacity of each bucket\n",
    "bucket_number = 2 #Starting bucket ID's\n",
    "global_depth = 1 #Initial global depth\n",
    "\n",
    "# Initialization of buckets\n",
    "bucket1 = Bucket(local_depth=1, empty_spaces=bucket_capacity, index=[], id=1)\n",
    "bucket2 = Bucket(local_depth=1, empty_spaces=bucket_capacity, index=[], id=2)\n",
    "\n",
    "# Initialization of directory records\n",
    "directory_records = list()\n",
    "directory_records.append(DirectoryRecord(hash_prefix=0, bucket=bucket1))\n",
    "directory_records.append(DirectoryRecord(hash_prefix=1, bucket=bucket2))\n",
    "\n",
    "#Initialize directory\n",
    "directory = Directory(global_depth=1, directory_records=directory_records)\n",
    "\n",
    "\n",
    "def insert(index):\n",
    "    \n",
    "    global directory\n",
    "    global bucket_number\n",
    "    \n",
    "    t_id = index[0] # Gets ID from index\n",
    "    hash_key = hash_function(int(t_id)) # Converts ID into binary\n",
    "    hash_prefix = int(hash_key[-directory.global_depth:], 2) # Compute hash prefix based on global depth\n",
    "\n",
    "    bucket = directory.directory_records[hash_prefix].value # Get corresponding bucket\n",
    "    bucket.index.append(index) # Add index to the bucket\n",
    "    bucket.empty_spaces -= 1 # Decrease the empty spaces in the bucket\n",
    "\n",
    "    # If bucket is overloaded handle overflow\n",
    "    if bucket.empty_spaces < 0: \n",
    "        temp_memory = bucket.index[:]\n",
    "        bucket.empty_spaces = bucket_capacity\n",
    "        bucket.index = []\n",
    "        \n",
    "        if directory.global_depth > bucket.local_depth:\n",
    "            number_of_links = 2 ** (directory.global_depth - bucket.local_depth)\n",
    "            bucket.local_depth += 1\n",
    "            number_of_modify_links = number_of_links // 2\n",
    "\n",
    "            new_bucket = Bucket(local_depth=bucket.local_depth, index=[], empty_spaces=bucket_capacity, id=bucket_number)\n",
    "            bucket_number += 1\n",
    "\n",
    "            for directory_record in directory.directory_records:\n",
    "                if directory_record.value == bucket:\n",
    "                    if number_of_modify_links != 0:\n",
    "                        number_of_modify_links -= 1\n",
    "                    else:\n",
    "                        directory_record.value = new_bucket\n",
    "\n",
    "            for item in temp_memory:\n",
    "                insert(item)\n",
    "\n",
    "        elif directory.global_depth == bucket.local_depth:\n",
    "            new_directory_len = 2 * len(directory.directory_records)\n",
    "            new_directory_records = []\n",
    "\n",
    "            for directory_record_number in range(new_directory_len):\n",
    "                new_directory_records.append(DirectoryRecord(\n",
    "                    hash_prefix=directory_record_number, \n",
    "                    bucket=Bucket(local_depth=1, index=[], empty_spaces=bucket_capacity, id=bucket_number)\n",
    "                ))\n",
    "                bucket_number += 1\n",
    "            \n",
    "            new_directory = Directory(global_depth=directory.global_depth + 1, directory_records=new_directory_records)\n",
    "\n",
    "            for directory_record in directory.directory_records:\n",
    "                hashkey1 = '0' + hash_function(directory_record.hash_prefix)\n",
    "                hashkey2 = '1' + hash_function(directory_record.hash_prefix)\n",
    "                new_index1 = int(hashkey1[-new_directory.global_depth:], 2)\n",
    "                new_index2 = int(hashkey2[-new_directory.global_depth:], 2)\n",
    "\n",
    "                new_directory.directory_records[new_index1].value = directory_record.value\n",
    "                new_directory.directory_records[new_index2].value = directory_record.value\n",
    "\n",
    "            directory = new_directory\n",
    "\n",
    "            for item in temp_memory:\n",
    "                insert(item)\n",
    "    print_directory()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for record in directory.directory_records:\n",
    "            temp_memory.extend(record.value.index)\n",
    "            record.value.index = [:] # Clear the bucket\n",
    "            record.value.empty_spaces = bucket_capacity # Reset empty spaces\n",
    "\n",
    "        # Store the overflowing index\n",
    "        temp_memory.append(index)\n",
    "        \n",
    "        if directory.global_depth > bucket.local_depth: \n",
    "            number_of_links = 2 ** (directory.global_depth - bucket.local_depth) # Calculate how many directory records point to the bucket\n",
    "            bucket.local_depth += 1 # Increase the local depth of the bucket\n",
    "            number_of_modify_links = number_of_links // 2 # Calculates the new number of links for the bucket\n",
    "            \n",
    "            # Creates new bucket\n",
    "            new_bucket = Bucket(local_depth=bucket.local_depth, index=[], empty_spaces=bucket_capacity, id=bucket_number)\n",
    "            bucket_number += 1\n",
    "            \n",
    "            # Updates directory records with new bucket references\n",
    "            for directory_record in directory.directory_records: # Iterates over each directory record\n",
    "                if directory_record.value == bucket: # Check if each directory record references the bucket that overflowed\n",
    "                    if number_of_modify_links != 0: # If there are still links to modify\n",
    "                        number_of_modify_links -= 1 \n",
    "                    else:\n",
    "                        directory_record.value = new_bucket # Assign new bucket to directory record\n",
    "            \n",
    "        elif directory.global_depth == bucket.local_depth: \n",
    "            directory.global_depth += 1\n",
    "            new_directory_records = []\n",
    "            for record in directory.directory_records:\n",
    "                new_directory_records.append(DirectoryRecord(hash_prefix=record.hash_prefix, bucket=record.value))\n",
    "                new_directory_records.append(DirectoryRecord(hash_prefix=record.hash_prefix, bucket=record.value))\n",
    "            \n",
    "            directory.directory_records = new_directory_records\n",
    "            \n",
    "        # Reinsert all items\n",
    "        for item in temp_memory:\n",
    "            insert(item)\n",
    "    else:\n",
    "        print_directory()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def print_directory():\n",
    "    global directory\n",
    "    print(\"Directory State:\")\n",
    "    for record in directory.directory_records:\n",
    "        print(f\"Binary: {record.hash_prefix}, Bucket ID: {record.value.id}, Local Depth: {record.value.local_depth}, Values: {record.value.index}\")\n",
    "    print()    \n",
    "    \n",
    "\n",
    "# Inserting values and printing the directory state\n",
    "#for value in values:\n",
    "insert([16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454c61bb-3a30-4531-9f77-f2226a96bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [22]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9672de9-f2d5-4a0c-a968-795a6fe46b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [22], [26]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608842ab-1e6c-499b-912c-1122757309dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16]]\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: []\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: []\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16]]\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16]]\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20]]\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [20]]\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [20]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d54ed80-e6ed-434f-9a25-5513becd44de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [20]]\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [20]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26], [3]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[22], [26], [3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ece1b7ea-d63f-4b6b-957d-3140d2670a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 1, Values: [[3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e0bb013-5f7b-4b3c-b2b4-3073a2d1fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 1, Values: [[3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d28c95bf-6e14-4b2d-8b0d-e8a431a0ac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 1, Values: [[3], [11]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ab2b1f-4846-48d0-a24b-81239e916596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 1, Values: [[3], [11]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be89250a-1033-49d9-ba5a-80e0867e0ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 1, Values: [[3], [11], [19]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bbbfbc3-5d51-438f-a5d0-8963ea148cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 1, Values: [[3], [11], [19]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9fbe781-ec92-4df2-8ec1-c2fd2e99e98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11], [19]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3]]\n",
      "Binary: 4, Bucket ID: 11, Local Depth: 1, Values: []\n",
      "Binary: 5, Bucket ID: 12, Local Depth: 1, Values: []\n",
      "Binary: 6, Bucket ID: 13, Local Depth: 1, Values: []\n",
      "Binary: 7, Bucket ID: 14, Local Depth: 1, Values: []\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11]]\n",
      "Binary: 4, Bucket ID: 11, Local Depth: 1, Values: []\n",
      "Binary: 5, Bucket ID: 12, Local Depth: 1, Values: []\n",
      "Binary: 6, Bucket ID: 13, Local Depth: 1, Values: []\n",
      "Binary: 7, Bucket ID: 14, Local Depth: 1, Values: []\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11], [19]]\n",
      "Binary: 4, Bucket ID: 11, Local Depth: 1, Values: []\n",
      "Binary: 5, Bucket ID: 12, Local Depth: 1, Values: []\n",
      "Binary: 6, Bucket ID: 13, Local Depth: 1, Values: []\n",
      "Binary: 7, Bucket ID: 14, Local Depth: 1, Values: []\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11], [19]]\n",
      "Binary: 4, Bucket ID: 11, Local Depth: 1, Values: []\n",
      "Binary: 5, Bucket ID: 12, Local Depth: 1, Values: []\n",
      "Binary: 6, Bucket ID: 13, Local Depth: 1, Values: []\n",
      "Binary: 7, Bucket ID: 14, Local Depth: 1, Values: [[47]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11], [19]]\n",
      "Binary: 4, Bucket ID: 11, Local Depth: 1, Values: []\n",
      "Binary: 5, Bucket ID: 12, Local Depth: 1, Values: []\n",
      "Binary: 6, Bucket ID: 13, Local Depth: 1, Values: []\n",
      "Binary: 7, Bucket ID: 14, Local Depth: 1, Values: [[47]]\n",
      "\n",
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11], [19]]\n",
      "Binary: 4, Bucket ID: 11, Local Depth: 1, Values: []\n",
      "Binary: 5, Bucket ID: 12, Local Depth: 1, Values: []\n",
      "Binary: 6, Bucket ID: 13, Local Depth: 1, Values: []\n",
      "Binary: 7, Bucket ID: 14, Local Depth: 1, Values: [[47]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79670555-644a-4363-b402-febe1bdc5a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory State:\n",
      "Binary: 0, Bucket ID: 1, Local Depth: 1, Values: [[16], [20], [12]]\n",
      "Binary: 1, Bucket ID: 2, Local Depth: 1, Values: [[1], [13]]\n",
      "Binary: 2, Bucket ID: 4, Local Depth: 1, Values: [[22], [26], [38]]\n",
      "Binary: 3, Bucket ID: 5, Local Depth: 2, Values: [[3], [11], [19]]\n",
      "Binary: 4, Bucket ID: 11, Local Depth: 1, Values: []\n",
      "Binary: 5, Bucket ID: 12, Local Depth: 1, Values: []\n",
      "Binary: 6, Bucket ID: 13, Local Depth: 1, Values: [[46]]\n",
      "Binary: 7, Bucket ID: 14, Local Depth: 1, Values: [[47]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert([46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7a10f24-ed23-41d9-8a12-e561fb4ba866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When expanding the directory, I can't seem to successfully store and clear all\n",
    "# of the values in the buckets, as seen in insert 47, only the contents of bucket 4 were \n",
    "#cleared and stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0aea0a1-06bc-4183-b836-94991aee59fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated page 0: [20 92]\n",
      "Generated page 1: [27 80]\n",
      "Generated page 2: [63  3]\n",
      "Generated page 3: [91 73]\n",
      "Generated page 4: [69  2]\n",
      "Generated page 5: [30 25]\n",
      "Generated page 6: [56 11]\n",
      "Generated page 7: [36 70]\n",
      "Sorted page 0: [20 92]\n",
      "Sorted page 1: [27 80]\n",
      "Sorted page 2: [ 3 63]\n",
      "Sorted page 3: [73 91]\n",
      "Sorted page 4: [ 2 69]\n",
      "Sorted page 5: [25 30]\n",
      "Sorted page 6: [11 56]\n",
      "Sorted page 7: [36 70]\n",
      "Data in sorted_data.bin: [ 2  3 11 20 25 27 30 36 56 63 69 70 73 80 91 92]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import os\n",
    "\n",
    "#Generates data\n",
    "def generate_data(num_pages, page_size, output_directory): \n",
    "    os.makedirs(output_directory, exist_ok=True) #Creates output directory\n",
    "    for i in range(num_pages): #Creates multiple pages\n",
    "        data = np.random.randint(0, 100, page_size) #Generates a page of random numbers between 0-100\n",
    "        np.save(os.path.join(output_directory, f'page_{i}.npy'), data) #Saves the data into a numpy file\n",
    "        print(f'Generated page {i}: {data}') #Print the generated page\n",
    "\n",
    "#Sorts data\n",
    "def sort_pages(input_directory, num_pages):\n",
    "    for i in range(num_pages): #Iterates over each page\n",
    "        data = np.load(os.path.join(input_directory, f'page_{i}.npy')) #Load data from the numpy files\n",
    "        sorted_data = np.sort(data) #Sort the data\n",
    "        np.save(os.path.join(input_directory, f'sorted_page_{i}.npy'), sorted_data) #Save the sorted data into a new file\n",
    "        print(f'Sorted page {i}: {sorted_data}') #Prints sorted data\n",
    "\n",
    "#Merges the sorted data        \n",
    "def merge_pages(input_directory, num_pages, buffer_size, output_file):\n",
    "    #Opens all the sorted data files\n",
    "    open_files = [open(os.path.join(input_directory, f'sorted_page_{i}.npy'), 'rb') for i in range(num_pages)]\n",
    "    with open(output_file, 'wb') as out_file: #Allows the program to edit the files\n",
    "        buffers = [np.load(f) for f in open_files] #Load the sorted data into buffers\n",
    "        min_heap = [] #Initialize min-heap\n",
    "        for i, buffer in enumerate(buffers): #Iterate over each buffer with its index\n",
    "            if buffer.size > 0: #Check if buffer is not empty\n",
    "                heapq.heappush(min_heap, (buffer[0], i, 0)) #Push the first element of buffer into min-heap\n",
    "        \n",
    "        while min_heap: #While there are elements in min-heap\n",
    "            val, buffer_index, element_index = heapq.heappop(min_heap) #Remove the smallest element from the heap\n",
    "            out_file.write(val.tobytes()) #Write it to the output file\n",
    "            next_element_index = element_index + 1 #Calculate the index of the next element in the same buffer\n",
    "            if next_element_index < buffers[buffer_index].size: #Check if there are more elements in the buffer\n",
    "                heapq.heappush(min_heap, (buffers[buffer_index][next_element_index], buffer_index, next_element_index))\n",
    "                #Push the next value into min-heap\n",
    "                \n",
    "def external_merge_sort(input_directory, num_pages, page_size, buffer_size, output_file):\n",
    "    sort_pages(input_directory, num_pages)\n",
    "    merge_pages(input_directory, num_pages, buffer_size, output_file)\n",
    "\n",
    "def display_data(file_path):\n",
    "    data = np.fromfile(file_path, dtype=np.int32)\n",
    "    print(f'Data in {file_path}: {data}')\n",
    "\n",
    "#Example usage\n",
    "output_directory = 'data'\n",
    "generate_data(num_pages=8, page_size=2, output_directory=output_directory)\n",
    "external_merge_sort(input_directory=output_directory, num_pages=8, page_size=2, buffer_size=10, output_file='sorted_data.bin')\n",
    "\n",
    "# Display final merged data\n",
    "display_data('sorted_data.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64f4c7-14d5-46bc-8436-f965c5de99e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988aa942-0fec-4052-9327-d322f6c0f0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
